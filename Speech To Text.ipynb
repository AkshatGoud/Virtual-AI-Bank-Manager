{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper Large Model downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# This downloads the model and stores it locally\n",
    "model = whisper.load_model(\"base\")\n",
    "print(\"Whisper Large Model downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in /Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "import wave\n",
    "from openai import OpenAI\n",
    "import whisper\n",
    "import torch\n",
    "\n",
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(): #Function to record audio\n",
    "       \n",
    "    FORMAT = pyaudio.paInt16 # data format\n",
    "    CHANNELS = 1 # mono, change to 2 if you want stereo\n",
    "    RATE = 44100 # sample rate\n",
    "    CHUNK = 1024 # frames per buffer\n",
    "    RECORD_SECONDS = 5 # change this to the duration you want to record\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Start recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def convert_audio_to_text():\n",
    "    # Load the audio file\n",
    "    audio_file = \"output.wav\"\n",
    "    audio, samplerate = sf.read(audio_file)\n",
    "\n",
    "    # Convert the audio to text\n",
    "    openai = OpenAI()\n",
    "    text = openai.speech_to_text(audio, samplerate)\n",
    "\n",
    "    print(\"Transcription:\")\n",
    "    print(text)\"\"\"\n",
    "\n",
    "def convert_audio_to_text(audiofile):\n",
    "    \"\"\"Converts an audio file to text using the locally downloaded Whisper model.\"\"\"\n",
    "    \n",
    "    # Load the locally stored Whisper large model\n",
    "    model = whisper.load_model(\"base\")  # No API key required\n",
    "    \n",
    "    # Transcribe the audio\n",
    "    result = model.transcribe(audiofile)\n",
    "    #result = model.transcribe(\"your-audio-file.wav\", )\n",
    "\n",
    "\n",
    "    return result[\"text\"]  # Extract and return transcribed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "def convert_mp3_to_wav(input_mp3, output_wav):\n",
    "    \"\"\"Converts an MP3 file to WAV format using FFmpeg.\"\"\"\n",
    "    try:\n",
    "        ffmpeg.input(input_mp3).output(output_wav, ar=16000, ac=1, format='wav').run(overwrite_output=True)\n",
    "        print(f\"Conversion successful: {output_wav}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    audio_path = \"How To Convert MP4 To Text.mp3\" \n",
    "    convert_mp3_to_wav(audio_path, \"output.wav\")\n",
    "    transcribed_text = convert_audio_to_text(\"output.wav\")\n",
    "    print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mp3, from 'How To Convert MP4 To Text.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:04:36.90, start: 0.025057, bitrate: 192 kb/s\n",
      "  Stream #0:0: Audio: mp3 (mp3float), 44100 Hz, stereo, fltp, 192 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc60.31\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'output.wav':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x14be268b0] video:0KiB audio:8652KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000880%\n",
      "size=    8652KiB time=00:04:36.85 bitrate= 256.0kbits/s speed=1.19e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful: output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, hello, hello, I'm Tyler Bryden. I hope you have a wonderful day. In this video, I'm going to show you how you can easily convert an MP4 to text and you're asking maybe who am I? Well, I am lucky enough to work at a great company called Speak AI. I helped found this company and we work with over 10,000 teams, organizations to use transcription and natural language processing to do some awesome stuff with audio video and text data. And if you are interested in converting MP4 to text, it's very easy to do with the platform. We have a dedicated landing page with a guide on how to do it. And if you want to start that process, very simply you can hit the Start Free Trial. If you don't have an account yet 14 day free trial, 30 minutes free, so if it's under 30 minutes, you can easily upload that right away. Or if you already have an account, thank you very much, you can log in. And when you log in, what's going to happen is you're going to be taken to this dashboard area. And there's a bunch of quick captions here. In this video specifically, we can hit up at the top, you can capture a new upload or I can just hit the quick action piece here. I can go new upload. I can upload the file and it's going to open my file explorer. We'll do the same thing in Finder if you're on Mac. I have nicely labeled everything here and I've got a sample little video MP4 file that is ready to go. Now, if you are in different languages, you can easily change those languages. This one is in English. And by default, this file is going to go into an unassigned folder. In my case, I'm actually going to say, hey, you know what, I want to go to the demo media file. And then I'm ready to upload and proceed. So this will take a second. It's a very short video. You have a credit card on the account. You can, and it's over the 30 minutes. If you're doing a free trial, you can use that credit card to pay or there's a really nice way to add a balance on the account and just use it from there. I'll drop a link in the description below. Once that is good to go, I can hit confirm transactional success. We'll say success. We'll finalize your upload. Again, should be pretty quick and simple for an eight second video like this. You can actually go to the folder now. You will receive an email when your transcription is ready. It will actually give you a link to that. So I have the demo video here. You can see that it is analyzing that video. It will take a couple of seconds slash minutes to do it because we do both the transcription and the analysis. That video comes back. You will be able to see all the speakers identified. We'll be able to see awesome keywords and everything extracted out of it. But more importantly for you because you're trying to convert an MP4 to text. The transcription is right here and ready to go. And in that case, you can instantly search. I can hit you product. I'll be into this to that specific moment. Listen to that piece. I can edit the transcription. If I want some awesome editing functions and there's great more tutorials and guides on that editing function. And then I can easily export to different formats, customize how I want to export that format. And even if I'm really focused on the quality of the transcription, maybe automated transcription isn't up. There's a professional transcription layer. You can easily and seamlessly or a professional transcription from our talented team. And you can also use what's really cool. This is an awesome release, this magic prompt system. So if you're looking for specific answers out of the file that you have, I can say, hey, give me the top action items. I can hit submit. And it's going to give me those top action items. So that's a very simple process of how to upload and convert an MP4 into text. Again, dashboard capture, new upload simply go ahead. And then the video once it's analyzed. I think this one will just be finished up. It's already to go. You can see the speakers. What I've talked about here and then the transcript and everything. So very quick, very simple. If you already have an account, you can log in and do this. And if you don't have an account on speak, feel encouraged to sign up. We really continue to grow the platform. It does some awesome stuff. We've got 10,000 people using it. And you can have a 14 day, no risk trial with 30 minutes included. We look forward to seeing on the platform. And if you ever need any help, feel encouraged to send us a message. We've got a great live chat, some great support and are always here and happy to help. Thank you so much.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
