{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "import wave\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import noisereduce as nr\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import subprocess\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def record_audio(): #Function to record audio\\n\\n    FORMAT = pyaudio.paInt16 # data format\\n    CHANNELS = 1 # mono, change to 2 if you want stereo\\n    RATE = 44100 # sample rate\\n    CHUNK = 1024 # frames per buffer\\n    RECORD_SECONDS = 25 # change this to the duration you want to record\\n    WAVE_OUTPUT_FILENAME = \"output.wav\"\\n\\n    audio = pyaudio.PyAudio()\\n\\n    # Start recording\\n    stream = audio.open(format=FORMAT, channels=CHANNELS,\\n                        rate=RATE, input=True,\\n                        frames_per_buffer=CHUNK)\\n    print(\"Recording...\")\\n\\n    frames = []\\n\\n    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\\n        data = stream.read(CHUNK)\\n        frames.append(data)\\n\\n    print(\"Finished recording.\")\\n\\n    # Stop recording\\n    stream.stop_stream()\\n    stream.close()\\n    audio.terminate()\\n\\n    # Save the recorded data as a WAV file\\n    with wave.open(WAVE_OUTPUT_FILENAME, \\'wb\\') as wf:\\n        wf.setnchannels(CHANNELS)\\n        wf.setsampwidth(audio.get_sample_size(FORMAT))\\n        wf.setframerate(RATE)\\n        wf.writeframes(b\\'\\'.join(frames))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def record_audio(): #Function to record audio\n",
    "       \n",
    "    FORMAT = pyaudio.paInt16 # data format\n",
    "    CHANNELS = 1 # mono, change to 2 if you want stereo\n",
    "    RATE = 44100 # sample rate\n",
    "    CHUNK = 1024 # frames per buffer\n",
    "    RECORD_SECONDS = 25 # change this to the duration you want to record\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Start recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_background_noise(input_audio_path, output_audio_path):\n",
    "    \"\"\"\n",
    "    Reduces background noise from an audio file and saves the cleaned version.\n",
    "\n",
    "    Args:\n",
    "        input_audio_path (str): Path to the input audio file (WAV format recommended).\n",
    "        output_audio_path (str): Path to save the cleaned audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        rate, data = wav.read(input_audio_path)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if len(data.shape) > 1:\n",
    "            data = np.mean(data, axis=1)\n",
    "\n",
    "        # Apply noise reduction\n",
    "        reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
    "\n",
    "        # Save the processed audio\n",
    "        wav.write(output_audio_path, rate, reduced_noise.astype(np.int16))\n",
    "        \n",
    "        print(f\"Noise reduction completed. Saved to: {output_audio_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example Usage\n",
    "# reduce_background_noise(\"input.wav\", \"output_clean.wav\")\n",
    "\n",
    "\n",
    "def convert_video_to_text(video_file):\n",
    "    \"\"\"\n",
    "    Extracts audio from a video file using ffmpeg and converts it to text using the locally downloaded Whisper model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if video file exists\n",
    "    if not os.path.isfile(video_file):\n",
    "        raise FileNotFoundError(f\"Error: The file '{video_file}' was not found.\")\n",
    "\n",
    "    # Define temporary audio output file\n",
    "    audio_path = \"temp_audio.wav\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Extract audio using ffmpeg\n",
    "        command = [\n",
    "            \"ffmpeg\", \"-i\", video_file, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", audio_path, \"-y\"\n",
    "        ]\n",
    "        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "        # Load Whisper model\n",
    "        model = whisper.load_model(\"large\")\n",
    "\n",
    "        reduce_background_noise(audio_path,audio_path)\n",
    "        # Transcribe the extracted audio\n",
    "        result = model.transcribe(\"temp_audio.wav\")\n",
    "\n",
    "        # Cleanup: Remove temporary audio file\n",
    "        os.remove(audio_path)\n",
    "\n",
    "        return result[\"text\"]  # Extract and return transcribed text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise reduction completed. Saved to: temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello, my name is Akshat Gowd. I have a salary of 20 lakhs.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_video_to_text(\"/Users/akshat/Developer/Python/CODE/Virtual AI Bank Manager/HTML/static/uploads/user_recorded.webm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "   # record_audio()\n",
    "    audio_path = \"output.wav\" \n",
    "    convert_mp3_to_wav(audio_path, \"output.wav\")\n",
    "    transcribed_text = convert_audio_to_text(\"output.wav\")\n",
    "    print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pyaudio\\nimport wave\\nimport threading\\n\\n# Audio settings\\nFORMAT = pyaudio.paInt16  # 16-bit audio\\nCHANNELS = 1  # Mono audio\\nRATE = 44100  # Sample rate (Hz)\\nCHUNK = 1024  # Frames per buffer\\nWAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\\n\\n# Initialize PyAudio\\naudio = pyaudio.PyAudio()\\nstream = None\\nframes = []\\nrecording = False\\n\\ndef start_recording():\\n    global stream, frames, recording\\n    if recording:\\n        print(\"Recording is already in progress...\")\\n        return\\n\\n    recording = True\\n    frames = []  # Clear previous recording\\n\\n    stream = audio.open(format=FORMAT, channels=CHANNELS,\\n                        rate=RATE, input=True,\\n                        frames_per_buffer=CHUNK)\\n\\n    print(\"üéôÔ∏è Recording started...\")\\n\\n    def record():\\n        while recording:\\n            data = stream.read(CHUNK)\\n            frames.append(data)\\n\\n    # Start recording in a separate thread\\n    threading.Thread(target=record, daemon=True).start()\\n\\ndef stop_recording():\\n    global stream, frames, recording\\n    if not recording:\\n        print(\"No recording is in progress.\")\\n        return\\n\\n    recording = False  # Stop recording loop\\n    stream.stop_stream()\\n    stream.close()\\n\\n    # Save the recording to a WAV file\\n    with wave.open(WAVE_OUTPUT_FILENAME, \\'wb\\') as wf:\\n        wf.setnchannels(CHANNELS)\\n        wf.setsampwidth(audio.get_sample_size(FORMAT))\\n        wf.setframerate(RATE)\\n        wf.writeframes(b\\'\\'.join(frames))\\n\\n    print(f\"‚úÖ Recording stopped and saved as {WAVE_OUTPUT_FILENAME}\")\\n\\n# Example Usage\\nstart_recording()  # Start recording\\ninput(\"Press Enter to stop recording...\\n\")  # Wait for user input\\nstop_recording()  # Stop recording and save file'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "\n",
    "# Audio settings\n",
    "FORMAT = pyaudio.paInt16  # 16-bit audio\n",
    "CHANNELS = 1  # Mono audio\n",
    "RATE = 44100  # Sample rate (Hz)\n",
    "CHUNK = 1024  # Frames per buffer\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "# Initialize PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = None\n",
    "frames = []\n",
    "recording = False\n",
    "\n",
    "def start_recording():\n",
    "    global stream, frames, recording\n",
    "    if recording:\n",
    "        print(\"Recording is already in progress...\")\n",
    "        return\n",
    "\n",
    "    recording = True\n",
    "    frames = []  # Clear previous recording\n",
    "\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"üéôÔ∏è Recording started...\")\n",
    "    \n",
    "    def record():\n",
    "        while recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "    # Start recording in a separate thread\n",
    "    threading.Thread(target=record, daemon=True).start()\n",
    "\n",
    "def stop_recording():\n",
    "    global stream, frames, recording\n",
    "    if not recording:\n",
    "        print(\"No recording is in progress.\")\n",
    "        return\n",
    "\n",
    "    recording = False  # Stop recording loop\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Save the recording to a WAV file\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(f\"‚úÖ Recording stopped and saved as {WAVE_OUTPUT_FILENAME}\")\n",
    "\n",
    "# Example Usage\n",
    "start_recording()  # Start recording\n",
    "input(\"Press Enter to stop recording...\\n\")  # Wait for user input\n",
    "stop_recording()  # Stop recording and save file\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
