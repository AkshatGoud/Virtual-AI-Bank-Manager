{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper Large Model downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# This downloads the model and stores it locally\n",
    "model = whisper.load_model(\"small\")\n",
    "print(\"Whisper Large Model downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in /Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import soundfile as sf\n",
    "import pyaudio\n",
    "import wave\n",
    "from openai import OpenAI\n",
    "import whisper\n",
    "import torch\n",
    "\n",
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(): #Function to record audio\n",
    "       \n",
    "    FORMAT = pyaudio.paInt16 # data format\n",
    "    CHANNELS = 1 # mono, change to 2 if you want stereo\n",
    "    RATE = 44100 # sample rate\n",
    "    CHUNK = 1024 # frames per buffer\n",
    "    RECORD_SECONDS = 25 # change this to the duration you want to record\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Start recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def convert_audio_to_text():\n",
    "    # Load the audio file\n",
    "    audio_file = \"output.wav\"\n",
    "    audio, samplerate = sf.read(audio_file)\n",
    "\n",
    "    # Convert the audio to text\n",
    "    openai = OpenAI()\n",
    "    text = openai.speech_to_text(audio, samplerate)\n",
    "\n",
    "    print(\"Transcription:\")\n",
    "    print(text)\"\"\"\n",
    "\n",
    "def convert_audio_to_text(audiofile):\n",
    "    \"\"\"Converts an audio file to text using the locally downloaded Whisper model.\"\"\"\n",
    "    \n",
    "    # Load the locally stored Whisper large model\n",
    "    model = whisper.load_model(\"medium\")  # No API key required\n",
    "    \n",
    "    # Transcribe the audio\n",
    "    result = model.transcribe(audiofile)\n",
    "    #result = model.transcribe(\"your-audio-file.wav\", )\n",
    "\n",
    "\n",
    "    return result[\"text\"]  # Extract and return transcribed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "def convert_mp3_to_wav(input_mp3, output_wav):\n",
    "    \"\"\"Converts an MP3 file to WAV format using FFmpeg.\"\"\"\n",
    "    try:\n",
    "        ffmpeg.input(input_mp3).output(output_wav, ar=16000, ac=1, format='wav').run(overwrite_output=True)\n",
    "        print(f\"Conversion successful: {output_wav}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "   # record_audio()\n",
    "    audio_path = \"output.wav\" \n",
    "    convert_mp3_to_wav(audio_path, \"output.wav\")\n",
    "    transcribed_text = convert_audio_to_text(\"output.wav\")\n",
    "    print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x14cf0a1f0] Guessed Channel Layout: mono\n",
      "Input #0, wav, from 'output.wav':\n",
      "  Duration: 00:00:24.98, bitrate: 705 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "Output output.wav same as Input #0 - exiting\n",
      "FFmpeg cannot edit existing files in-place.\n",
      "Error opening output file output.wav.\n",
      "Error opening output files: Invalid argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during conversion: ffmpeg error (see stderr output for detail)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat/anaconda3/envs/VirtualAI/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My name is John Matthews and my date of birth is 17th February 2004. I am a salaried employee and my monthly income is 1.5 lakhs. The loan amount I am expecting is 20 lakhs and the purpose of this loan is a business loan.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Recording started...\n",
      "‚úÖ Recording stopped and saved as recorded_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "\n",
    "# Audio settings\n",
    "FORMAT = pyaudio.paInt16  # 16-bit audio\n",
    "CHANNELS = 1  # Mono audio\n",
    "RATE = 44100  # Sample rate (Hz)\n",
    "CHUNK = 1024  # Frames per buffer\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "# Initialize PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = None\n",
    "frames = []\n",
    "recording = False\n",
    "\n",
    "def start_recording():\n",
    "    \"\"\"Start recording audio.\"\"\"\n",
    "    global stream, frames, recording\n",
    "    if recording:\n",
    "        print(\"Recording is already in progress...\")\n",
    "        return\n",
    "\n",
    "    recording = True\n",
    "    frames = []  # Clear previous recording\n",
    "\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"üéôÔ∏è Recording started...\")\n",
    "    \n",
    "    def record():\n",
    "        while recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "    # Start recording in a separate thread\n",
    "    threading.Thread(target=record, daemon=True).start()\n",
    "\n",
    "def stop_recording():\n",
    "    \"\"\"Stop recording and save the audio file.\"\"\"\n",
    "    global stream, frames, recording\n",
    "    if not recording:\n",
    "        print(\"No recording is in progress.\")\n",
    "        return\n",
    "\n",
    "    recording = False  # Stop recording loop\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # Save the recording to a WAV file\n",
    "    with wave.open(WAVE_OUTPUT_FILENAME, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(f\"‚úÖ Recording stopped and saved as {WAVE_OUTPUT_FILENAME}\")\n",
    "\n",
    "# Example Usage\n",
    "start_recording()  # Start recording\n",
    "input(\"Press Enter to stop recording...\\n\")  # Wait for user input\n",
    "stop_recording()  # Stop recording and save file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
